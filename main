# Block 1: Required Package Installation
# Install necessary Python packages and system dependencies for document processing

# Install Google Translate library (specific version for compatibility)
!pip install googletrans==4.0.0-rc1

# Install Tesseract OCR and its Python wrapper
!pip install pytesseract
!sudo apt install tesseract-ocr  # Install Tesseract OCR engine
!pip install pytesseract         # Reinstall to ensure proper linking

# Install PDF processing and image manipulation libraries
!pip install pdf2image Pillow    # For PDF to image conversion and image processing

# Install Google Cloud Vision API for advanced OCR capabilities
!pip install --upgrade google-cloud-vision

# Install Poppler utilities (required by pdf2image for PDF processing)
!apt-get install -y poppler-utils

# Install language detection library
!pip install langdetect

# Block 2: File Upload Handler
# Enable file upload functionality in Google Colab
from google.colab import files
uploaded = files.upload()  # Opens file picker and returns uploaded file details

# Block 3: PDF to Image Conversion
from pdf2image import convert_from_path
from google.colab import files

# Define list of PDF files to process
pdf_files = [
    '24000001.pdf', '24000002.pdf', '24000003.pdf', '24000004.pdf', 
    '24000005.pdf', '24000006.pdf', '24000007.pdf', '24000008.pdf',
    '24000009.pdf', '24000010.pdf'
]

# Initialize list to store paths of all generated images
all_image_paths = []

# Process each PDF file
for pdf_path in pdf_files:
    # Convert PDF to images with 300 DPI resolution
    # Higher DPI provides better quality for OCR but increases processing time
    pages = convert_from_path(pdf_path, 300)
    
    # Process and save each page of the PDF
    image_paths = []
    for page_number, page in enumerate(pages):
        # Generate unique filename for each page
        image_path = f'{pdf_path}_page_{page_number + 1}.jpg'
        
        # Save page as JPEG image
        page.save(image_path, 'JPEG')
        
        # Store path for later processing
        image_paths.append(image_path)
    
    # Add paths from current PDF to master list
    all_image_paths.extend(image_paths)

# Return list of all generated image paths
all_image_paths  # Will be used in subsequent processing steps

# Block 4: Document Processing Setup and Core Classes

# Import required libraries
import pytesseract        # For OCR (optical character recognition)
from PIL import Image     # For image handling
from googletrans import Translator  # For language translation
from langdetect import detect      # For language detection
import spacy             # For NLP tasks and named entity recognition
import re                # For regular expression operations
import json              # For JSON data handling
import logging           # For application logging
from typing import Dict, Tuple, Optional, List  # For type hints
from dataclasses import dataclass   # For creating data classes
from datetime import datetime       # For timestamp generation
from pathlib import Path           # For file path handling

# Configure logging system for tracking execution and debugging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Define data structure for storing extracted document information
@dataclass
class DocumentInfo:
    image_path: str              # Path to the processed image
    company_name: Optional[str]  # Extracted company name (if found)
    company_identifier: Optional[str]  # Company registration number or identifier
    document_purpose: str        # Main purpose of the document
    purpose_details: Dict        # Additional details about the document purpose

# Main class for handling document information extraction
class DocumentExtractor:
    # Define regex patterns for extracting specific information
    PATTERNS = {
        'company_id': r'(?i)(?:company\s+identifier|registration\s+number|company\s+number)\s*:?\s*([\d\s-]+)',
        'position': r'(?i)position\s*:?\s*([\w\s,.-]+?)(?:\.|$|\n)',
        'effective_date': r'(?i)(?:effective\s+date|date\s+of\s+(?:appointment|resignation))\s*:?\s*([\d\s\w,.-]+?)(?:\.|$|\n)',
        'director_name': r'(?i)(?:director\s+name|name\s+of\s+director)\s*:?\s*([\w\s,.-]+?)(?:\.|$|\n)',
        'address': r'(?i)(?:address|residential\s+address)\s*:?\s*([\w\s,.-]+?)(?:\.|$|\n)',
        'nationality': r'(?i)nationality\s*:?\s*([\w\s]+?)(?:\.|$|\n)',
        'birth_date': r'(?i)(?:date\s+of\s+birth|birth\s+date)\s*:?\s*([\d\s\w,.-]+?)(?:\.|$|\n)'
    }

    # Define keywords for identifying document purposes
    PURPOSE_KEYWORDS = {
        'appointment': ['appointment', 'new director', 'appointment of director'],
        'resignation': ['resignation', 'cessation', 'stepping down'],
        'change': ['change of', 'amendment', 'modification'],
        'meeting': ['annual general meeting', 'extraordinary general meeting', 'board meeting'],
        'share': ['share allotment', 'transfer of shares', 'share structure']
    }

    def __init__(self):
        """Initialize document processor with required models and tools"""
        try:
            # Load English language model for NLP tasks
            self.nlp = spacy.load('en_core_web_sm')
        except OSError:
            logger.error("Failed to load spaCy model. Please install it using: python -m spacy download en_core_web_sm")
            raise
        
        # Initialize translator for handling non-English documents
        self.translator = Translator()

    def extract_using_pattern(self, text: str, pattern: str) -> Optional[str]:
        """Extract text matching a specific regex pattern"""
        match = re.search(pattern, text)
        return match.group(1).strip() if match else None

    def extract_company_name(self, text: str) -> Optional[str]:
        """Extract company name using NLP and pattern matching"""
        doc = self.nlp(text)
        
        # Find all organization entities in the text
        org_entities = [ent.text for ent in doc.ents if ent.label_ == "ORG"]
        
        if org_entities:
            # Look for explicit company name declarations
            company_pattern = r'(?i)company\s+name\s*:\s*([\w\s]+)(?:\.|$|\n)'
            explicit_company = self.extract_using_pattern(text, company_pattern)
            
            # Return explicit company name if found and valid
            if explicit_company and explicit_company in org_entities:
                return explicit_company
            
            # Fall back to first organization found
            return org_entities[0]
        
        return None

    def identify_document_purpose(self, text: str) -> Tuple[str, Dict]:
        """Determine document type and extract relevant details"""
        text_lower = text.lower()
        purpose_details = {}
        identified_purposes = []

        # Check text against known document types
        for purpose_type, keywords in self.PURPOSE_KEYWORDS.items():
            if any(keyword in text_lower for keyword in keywords):
                identified_purposes.append(purpose_type)
                # Extract additional details based on document type
                purpose_details.update(self._extract_purpose_specific_details(text, purpose_type))

        return (
            ", ".join(identified_purposes) if identified_purposes else "Purpose not identified",
            purpose_details
        )

    def _extract_purpose_specific_details(self, text: str, purpose_type: str) -> Dict:
    """Extract details specific to the document purpose.
    
    This method processes text differently based on document type (appointment/resignation)
    and extracts relevant information using predefined regex patterns.
    
    Args:
        text (str): The OCR-extracted text from the document
        purpose_type (str): The type of document ('appointment' or 'resignation')
        
    Returns:
        Dict: Dictionary containing extracted details specific to the document type
    """
    # Initialize details dictionary with capitalized document type
    details = {'Type': purpose_type.capitalize()}

    if purpose_type == 'appointment':
        # For appointment documents, extract comprehensive director information
        # including personal details and role information
        director_name = self.extract_using_pattern(text, self.PATTERNS['director_name'])
        position = self.extract_using_pattern(text, self.PATTERNS['position'])
        effective_date = self.extract_using_pattern(text, self.PATTERNS['effective_date'])
        nationality = self.extract_using_pattern(text, self.PATTERNS['nationality'])
        address = self.extract_using_pattern(text, self.PATTERNS['address'])

        # Only add non-None values to avoid empty fields
        if director_name:
            details['Director Name'] = director_name
        if position:
            details['Position'] = position
        if effective_date:
            details['Effective Date'] = effective_date
        if nationality:
            details['Nationality'] = nationality
        if address:
            details['Address'] = address

    elif purpose_type == 'resignation':
        # For resignation documents, we only need minimal information:
        # who is resigning and when it takes effect
        director_name = self.extract_using_pattern(text, self.PATTERNS['director_name'])
        effective_date = self.extract_using_pattern(text, self.PATTERNS['effective_date'])
        
        if director_name:
            details['Director Name'] = director_name
        if effective_date:
            details['Effective Date'] = effective_date

    return details

def process_document(self, image_path: str) -> DocumentInfo:
    """Process a single document and extract information.
    
    This method handles the complete document processing pipeline:
    1. Image loading and OCR
    2. Language detection and translation if needed
    3. Information extraction
    4. Error handling and reporting
    
    Args:
        image_path (str): Path to the image file to process
        
    Returns:
        DocumentInfo: Object containing all extracted information or error details
    """
    try:
        # Step 1: Load the image and perform OCR
        # Using PIL for image handling and pytesseract for text extraction
        image = Image.open(image_path)
        text = pytesseract.image_to_string(image)

        # Step 2: Language detection and translation
        # Attempt to detect non-English text and translate if necessary
        try:
            detected_language = detect(text)
            if detected_language != 'en':
                # Translate non-English text to English for consistent processing
                text = self.translator.translate(text, src=detected_language, dest='en').text
        except Exception as e:
            # Log warning but continue processing if language detection/translation fails
            logger.warning(f"Language detection/translation failed: {e}")

        # Step 3: Extract all relevant information from the processed text
        company_name = self.extract_company_name(text)
        company_identifier = self.extract_using_pattern(text, self.PATTERNS['company_id'])
        document_purpose, purpose_details = self.identify_document_purpose(text)

        # Return structured information in DocumentInfo object
        return DocumentInfo(
            image_path=image_path,
            company_name=company_name,
            company_identifier=company_identifier,
            document_purpose=document_purpose,
            purpose_details=purpose_details
        )

    except Exception as e:
        # Handle any processing errors by returning DocumentInfo with error details
        logger.error(f"Error processing document {image_path}: {e}")
        return DocumentInfo(
            image_path=image_path,
            company_name=None,
            company_identifier=None,
            document_purpose="Error processing document",
            purpose_details={"error": str(e)}
        )

def main():
    """Main execution function for batch document processing.
    
    This function:
    1. Sets up the output directory
    2. Initializes the document extractor
    3. Processes multiple documents in batch
    4. Saves results to a timestamped JSON file
    """
    # Create output directory if it doesn't exist
    output_dir = Path("extracted_results")
    output_dir.mkdir(exist_ok=True)
    
    # Initialize our document extraction system
    extractor = DocumentExtractor()
    
    # Track all processing results
    all_results = []
    # Generate timestamp for unique output file naming
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # List of all document images to process
    # Note: These appear to be PDF pages converted to images
    image_paths = [
        '24000001.pdf_page_1.jpg',
        '24000002.pdf_page_1.jpg',
        '24000003.pdf_page_1.jpg',
        '24000004.pdf_page_1.jpg',
        '24000005.pdf_page_1.jpg',
        '24000006.pdf_page_1.jpg',
        '24000006.pdf_page_2.jpg',
        '24000007.pdf_page_1.jpg',
        '24000007.pdf_page_2.jpg',
        '24000007.pdf_page_3.jpg',
        '24000007.pdf_page_4.jpg',
        '24000008.pdf_page_1.jpg',
        '24000009.pdf_page_1.jpg',
        '24000010.pdf_page_1.jpg'
    ]

    # Process each document and collect results
    for image_path in image_paths:
        logger.info(f"Processing {image_path}...")
        result = extractor.process_document(image_path)
        all_results.append(result.__dict__)

    # Save all processing results to a JSON file
    output_file = output_dir / f"extracted_info_{timestamp}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=4)
    
    logger.info(f"Results saved to {output_file}")

if __name__ == "__main__":
    main()
