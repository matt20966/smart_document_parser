#Block 1
pip installs
!pip install googletrans==4.0.0-rc1
!pip install pytesseract
!sudo apt install tesseract-ocr
!pip install pytesseract
!pip install pdf2image Pillow
!pip install --upgrade google-cloud-vision
!apt-get install -y poppler-utils
!pip install langdetect

#Block 2
from google.colab import files
uploaded = files.upload()


#Block3
from pdf2image import convert_from_path
from google.colab import files

# List of PDF files you want to process
pdf_files = ['24000001.pdf', '24000002.pdf', '24000003.pdf', '24000004.pdf', 
             '24000005.pdf', '24000006.pdf', '24000007.pdf', '24000008.pdf',
             '24000009.pdf', '24000010.pdf']

# Initialize a list to store image paths for all PDFs
all_image_paths = []

# Loop through each PDF and convert pages to images
for pdf_path in pdf_files:
    # Convert the PDF to images (you can adjust the DPI if necessary)
    pages = convert_from_path(pdf_path, 300)  # 300 DPI is good for OCR quality

    # Save each page as an image
    image_paths = []
    for page_number, page in enumerate(pages):
        image_path = f'{pdf_path}_page_{page_number + 1}.jpg'  # Unique name for each page
        page.save(image_path, 'JPEG')
        image_paths.append(image_path)
    
    # Add the paths of images for this PDF to the overall list
    all_image_paths.extend(image_paths)

# Output paths of all saved images
all_image_paths

#Block 4
import pytesseract
from PIL import Image
from googletrans import Translator
from langdetect import detect
import spacy
import re
import json
import logging
from typing import Dict, Tuple, Optional, List
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class DocumentInfo:
    image_path: str
    company_name: Optional[str]
    company_identifier: Optional[str]
    document_purpose: str
    purpose_details: Dict

class DocumentExtractor:
    # Regular expression patterns
    PATTERNS = {
        'company_id': r'(?i)(?:company\s+identifier|registration\s+number|company\s+number)\s*:?\s*([\d\s-]+)',
        'position': r'(?i)position\s*:?\s*([\w\s,.-]+?)(?:\.|$|\n)',
        'effective_date': r'(?i)(?:effective\s+date|date\s+of\s+(?:appointment|resignation))\s*:?\s*([\d\s\w,.-]+?)(?:\.|$|\n)',
        'director_name': r'(?i)(?:director\s+name|name\s+of\s+director)\s*:?\s*([\w\s,.-]+?)(?:\.|$|\n)',
        'address': r'(?i)(?:address|residential\s+address)\s*:?\s*([\w\s,.-]+?)(?:\.|$|\n)',
        'nationality': r'(?i)nationality\s*:?\s*([\w\s]+?)(?:\.|$|\n)',
        'birth_date': r'(?i)(?:date\s+of\s+birth|birth\s+date)\s*:?\s*([\d\s\w,.-]+?)(?:\.|$|\n)'
    }

    PURPOSE_KEYWORDS = {
        'appointment': ['appointment', 'new director', 'appointment of director'],
        'resignation': ['resignation', 'cessation', 'stepping down'],
        'change': ['change of', 'amendment', 'modification'],
        'meeting': ['annual general meeting', 'extraordinary general meeting', 'board meeting'],
        'share': ['share allotment', 'transfer of shares', 'share structure']
    }

    def __init__(self):
        """Initialize the document extractor with necessary models and tools."""
        try:
            self.nlp = spacy.load('en_core_web_sm')
        except OSError:
            logger.error("Failed to load spaCy model. Please install it using: python -m spacy download en_core_web_sm")
            raise

        self.translator = Translator()

    def extract_using_pattern(self, text: str, pattern: str) -> Optional[str]:
        """Extract information using a regex pattern."""
        match = re.search(pattern, text)
        return match.group(1).strip() if match else None

    def extract_company_name(self, text: str) -> Optional[str]:
        """Extract company name using spaCy and additional rules."""
        doc = self.nlp(text)
        
        # First try to find organization entities
        org_entities = [ent.text for ent in doc.ents if ent.label_ == "ORG"]
        
        if org_entities:
            # Prioritize organizations that appear after "Company Name:" or similar patterns
            company_pattern = r'(?i)company\s+name\s*:\s*([\w\s]+)(?:\.|$|\n)'
            explicit_company = self.extract_using_pattern(text, company_pattern)
            
            if explicit_company and explicit_company in org_entities:
                return explicit_company
            
            return org_entities[0]  # Return the first organization found
        
        return None

    def identify_document_purpose(self, text: str) -> Tuple[str, Dict]:
        """Identify document purpose and extract relevant details."""
        text_lower = text.lower()
        purpose_details = {}
        identified_purposes = []

        # Check for each purpose type
        for purpose_type, keywords in self.PURPOSE_KEYWORDS.items():
            if any(keyword in text_lower for keyword in keywords):
                identified_purposes.append(purpose_type)
                purpose_details.update(self._extract_purpose_specific_details(text, purpose_type))

        return (
            ", ".join(identified_purposes) if identified_purposes else "Purpose not identified",
            purpose_details
        )

    def _extract_purpose_specific_details(self, text: str, purpose_type: str) -> Dict:
        """Extract details specific to the document purpose."""
        details = {'Type': purpose_type.capitalize()}

        if purpose_type == 'appointment':
            director_name = self.extract_using_pattern(text, self.PATTERNS['director_name'])
            position = self.extract_using_pattern(text, self.PATTERNS['position'])
            effective_date = self.extract_using_pattern(text, self.PATTERNS['effective_date'])
            nationality = self.extract_using_pattern(text, self.PATTERNS['nationality'])
            address = self.extract_using_pattern(text, self.PATTERNS['address'])

            if director_name:
                details['Director Name'] = director_name
            if position:
                details['Position'] = position
            if effective_date:
                details['Effective Date'] = effective_date
            if nationality:
                details['Nationality'] = nationality
            if address:
                details['Address'] = address

        elif purpose_type == 'resignation':
            director_name = self.extract_using_pattern(text, self.PATTERNS['director_name'])
            effective_date = self.extract_using_pattern(text, self.PATTERNS['effective_date'])
            
            if director_name:
                details['Director Name'] = director_name
            if effective_date:
                details['Effective Date'] = effective_date

        return details

    def process_document(self, image_path: str) -> DocumentInfo:
        """Process a single document and extract information."""
        try:
            # Open and process image
            image = Image.open(image_path)
            text = pytesseract.image_to_string(image)

            # Detect and translate if necessary
            try:
                detected_language = detect(text)
                if detected_language != 'en':
                    text = self.translator.translate(text, src=detected_language, dest='en').text
            except Exception as e:
                logger.warning(f"Language detection/translation failed: {e}")

            # Extract information
            company_name = self.extract_company_name(text)
            company_identifier = self.extract_using_pattern(text, self.PATTERNS['company_id'])
            document_purpose, purpose_details = self.identify_document_purpose(text)

            return DocumentInfo(
                image_path=image_path,
                company_name=company_name,
                company_identifier=company_identifier,
                document_purpose=document_purpose,
                purpose_details=purpose_details
            )

        except Exception as e:
            logger.error(f"Error processing document {image_path}: {e}")
            return DocumentInfo(
                image_path=image_path,
                company_name=None,
                company_identifier=None,
                document_purpose="Error processing document",
                purpose_details={"error": str(e)}
            )

def main():
    # Create output directory for results
    output_dir = Path("extracted_results")
    output_dir.mkdir(exist_ok=True)
    
    # Initialize extractor
    extractor = DocumentExtractor()
    
    # Process all images
    all_results = []
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    image_paths = [
        '24000001.pdf_page_1.jpg',
        '24000002.pdf_page_1.jpg',
        '24000003.pdf_page_1.jpg',
        '24000004.pdf_page_1.jpg',
        '24000005.pdf_page_1.jpg',
        '24000006.pdf_page_1.jpg',
        '24000006.pdf_page_2.jpg',
        '24000007.pdf_page_1.jpg',
        '24000007.pdf_page_2.jpg',
        '24000007.pdf_page_3.jpg',
        '24000007.pdf_page_4.jpg',
        '24000008.pdf_page_1.jpg',
        '24000009.pdf_page_1.jpg',
        '24000010.pdf_page_1.jpg'
    ]

    for image_path in image_paths:
        logger.info(f"Processing {image_path}...")
        result = extractor.process_document(image_path)
        all_results.append(result.__dict__)

    # Save results to JSON file
    output_file = output_dir / f"extracted_info_{timestamp}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=4)
    
    logger.info(f"Results saved to {output_file}")

if __name__ == "__main__":
    main()
